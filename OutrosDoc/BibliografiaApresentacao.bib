
@article{barba_terminologies_2018,
	title = {Terminologies for Reproducible Research},
	url = {http://arxiv.org/abs/1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	journaltitle = {{arXiv}:1802.03311 [cs]},
	author = {Barba, Lorena A.},
	urldate = {2021-08-27},
	date = {2018-02-09},
	eprinttype = {arxiv},
	eprint = {1802.03311},
	keywords = {Computer Science - Digital Libraries},
	file = {arXiv Fulltext PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\KMRUXVDE\\Barba - 2018 - Terminologies for Reproducible Research.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\MY2PUJDG\\1802.html:text/html},
}

@article{drummond_reproducible_2018,
	title = {Reproducible research: a minority opinion},
	volume = {30},
	issn = {0952-813X},
	url = {https://doi.org/10.1080/0952813X.2017.1413140},
	doi = {10.1080/0952813X.2017.1413140},
	shorttitle = {Reproducible research},
	abstract = {Reproducible research, a growing movement within many scientific fields, including machine learning, would require the code, used to generate the experimental results, be published along with any paper. Probably the most compelling argument for this is that it is simply following good scientific practice, established over the years by the greats of science. The implication is that failure to follow such a practice is unscientific, not a label any machine learning researchers would like to carry. It is further claimed that misconduct is causing a growing crisis of confidence in science. That, without this practice being enforced, science would inevitably fall into disrepute. This viewpoint is becoming ubiquitous but here I offer a differing opinion. I argue that far from being central to science, what is being promulgated is a narrow interpretation of how science works. I contend that the consequences are somewhat overstated. I would also contend that the effort necessary to meet the movement’s aims, and the general attitude it engenders would not serve well any of the research disciplines, including our own.},
	pages = {1--11},
	number = {1},
	journaltitle = {Journal of Experimental \& Theoretical Artificial Intelligence},
	author = {Drummond, Chris},
	urldate = {2021-08-27},
	date = {2018-01-02},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/0952813X.2017.1413140},
	keywords = {machine learning, reproducible research, scientific communication, scientific evaluation},
	file = {Full Text PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\NSE62UUF\\Drummond - 2018 - Reproducible research a minority opinion.pdf:application/pdf;Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\LU9LA7DC\\0952813X.2017.html:text/html},
}

@report{granell_reproducible_2018,
	title = {Reproducible Research is like riding a bike},
	institution = {{PeerJ} Preprints},
	author = {Granell, Carlos and Nüst, Daniel and Ostermann, Frank O. and Sileryte, Rusne},
	date = {2018},
	file = {Full Text:C\:\\Users\\e-CJD\\Zotero\\storage\\P8RZIYLC\\Granell et al. - 2018 - Reproducible Research is like riding a bike.pdf:application/pdf},
}

@article{sui_reproducibility_2021,
	title = {Reproducibility and Replicability in the Context of the Contested Identities of Geography},
	volume = {111},
	issn = {2469-4452},
	url = {https://doi.org/10.1080/24694452.2020.1806024},
	doi = {10.1080/24694452.2020.1806024},
	abstract = {This article situates the current discussion of reproducibility and replicability taking place across the sciences within geographers’ enduring discussion of nomothetic and idiographic approaches, best exemplified by the Hartshorne–Schaefer debate. Although the Hartshorne–Schaefer debate retrospectively set the stage for the development of geography from the 1950s to the present, it is surprising that direct discussions of reproducibility and replicability remain mostly absent from the geographic literature. Drawing from recent literature on reproducibility and replicability in the humanities and physical, social, and computational sciences, it is argued that a deeper focus on these issues will have varied impacts on the discipline. Adopting and improving reproducible practices in geographic research reliant on scientific methods will align geographic research with mainstream scientific inquiry. The discipline’s ever-growing diversity of theoretical perspectives and problem domains also makes it likely that a significant portion of geographic research, like many other fields in science, might not be affected by the issues and concerns of reproducibility and replicability. Moving forward, geographic research might continue to benefit from a pluralist framework that embraces both the nomothetic and idiographic approaches, particularly in a broader research environment increasingly defined by disciplinary synthesis and convergence.},
	pages = {1275--1283},
	number = {5},
	journaltitle = {Annals of the American Association of Geographers},
	author = {Sui, Daniel and Kedron, Peter},
	urldate = {2021-08-27},
	date = {2021-07-29},
	note = {Publisher: Taylor \& Francis
\_eprint: https://doi.org/10.1080/24694452.2020.1806024},
	keywords = {betweenness, {GIScience}, idiográfico, idiographic, interioridad, nomothetic, replicabilidad, replicability, reproducibilidad, reproducibility, {SIGciencia}, 中间性, 可再现性, 可重复性, 地理信息科学, 独特的, 理性的},
	file = {Full Text PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\M4GKHCK2\\Sui e Kedron - 2021 - Reproducibility and Replicability in the Context o.pdf:application/pdf;Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\DAWXFECT\\24694452.2020.html:text/html},
}

@article{sandve_ten_2013,
	title = {Ten Simple Rules for Reproducible Computational Research},
	volume = {9},
	issn = {1553-7358},
	url = {https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	pages = {e1003285},
	number = {10},
	journaltitle = {{PLOS} Computational Biology},
	shortjournal = {{PLOS} Computational Biology},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	urldate = {2021-08-27},
	date = {2013-10-24},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Archives, Computer and information sciences, Computer applications, Genome analysis, Habits, Replication studies, Reproducibility, Source code},
	file = {Full Text PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\M4XYHX7R\\Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf:application/pdf;Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\IZ7XNQSQ\\article.html:text/html},
}

@article{jasny_data_2011,
	title = {Data replication \& reproducibility. Again, and again, and again .... Introduction},
	volume = {334},
	issn = {1095-9203},
	url = {https://doi.org/10.1126/science.334.6060.1225},
	doi = {10.1126/science.334.6060.1225},
	pages = {1225},
	number = {6060},
	journaltitle = {Science (New York, N.Y.)},
	shortjournal = {Science},
	author = {Jasny, Barbara R and Chin, Gilbert and Chong, Lisa and Vignieri, Sacha},
	urldate = {2021-08-27},
	date = {2011-12-01},
	pmid = {22144612},
	file = {Texto completo:C\:\\Users\\e-CJD\\Zotero\\storage\\HGFRJ6D7\\Jasny et al. - 2011 - Data replication & reproducibility. Again, and aga.pdf:application/pdf},
}

@article{hail_reproducibility_2020,
	title = {Reproducibility in Accounting Research: Views of the Research Community},
	volume = {58},
	issn = {1475-679X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1475-679X.12305},
	doi = {10.1111/1475-679X.12305},
	shorttitle = {Reproducibility in Accounting Research},
	abstract = {We have little knowledge about the prevalence of irreproducibility in the accounting literature. To narrow this gap, we conducted a survey among the participants of the 2019 {JAR} Conference on their perceptions of the frequency, causes, and consequences of irreproducible research published in accounting journals. A majority of respondents believe that irreproducibility is common in the literature, constitutes a major problem, and receives too little attention. Most have encountered irreproducibility in the work of others (although not in their own work) but chose not to pursue their failed reproduction attempts to publication. Respondents believe irreproducibility results chiefly from career or publication incentives as well as from selective reporting of results. They also believe that practices like sharing code and data combined with stronger incentives to replicate the work of others would enhance reproducibility. The views of accounting researchers are remarkably similar to those expressed in a survey by the scientific journal Nature. We conclude by discussing the implications of our findings and provide several potential paths forward for the accounting research community.},
	pages = {519--543},
	number = {2},
	journaltitle = {Journal of Accounting Research},
	author = {Hail, Luzi and Lang, Mark and Leuz, Christian},
	urldate = {2021-08-27},
	date = {2020},
	langid = {english},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/1475-679X.12305},
	keywords = {reproducibility, accounting research, ethics, expert survey, publication process, replication, research methodology},
	file = {Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\MSCYTXFI\\1475-679X.html:text/html},
}

@article{kane_open_2009,
	title = {Open Source Finance},
	volume = {18},
	rights = {© 2009 Pageant Media Ltd},
	issn = {1068-0896, 2168-8613},
	url = {https://joi.pm-research.com/content/18/1/92},
	doi = {10.3905/JOI.2009.18.1.092},
	abstract = {{\textless}p{\textgreater}We survey the ways in which open source software and open source principles are becoming increasingly important for the financial industry. Finance professionals and academics who embrace open source are more likely to be successful than those who do not.{\textless}/p{\textgreater}},
	pages = {92--96},
	number = {1},
	journaltitle = {The Journal of Investing},
	author = {Kane, David and Masters, Joseph D.},
	urldate = {2021-08-27},
	date = {2009-02-28},
	langid = {english},
	note = {Publisher: Institutional Investor Journals Umbrella},
	file = {Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\5T3RIFPH\\92.html:text/html},
}

@article{liu_finrl_2020,
	title = {{FinRL}: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance},
	url = {http://arxiv.org/abs/2011.09607},
	shorttitle = {{FinRL}},
	abstract = {As deep reinforcement learning ({DRL}) has been recognized as an effective approach in quantitative finance, getting hands-on experiences is attractive to beginners. However, to train a practical {DRL} trading agent that decides where to trade, at what price, and what quantity involves error-prone and arduous development and debugging. In this paper, we introduce a {DRL} library {FinRL} that facilitates beginners to expose themselves to quantitative finance and to develop their own stock trading strategies. Along with easily-reproducible tutorials, {FinRL} library allows users to streamline their own developments and to compare with existing schemes easily. Within {FinRL}, virtual environments are configured with stock market datasets, trading agents are trained with neural networks, and extensive backtesting is analyzed via trading performance. Moreover, it incorporates important trading constraints such as transaction cost, market liquidity and the investor's degree of risk-aversion. {FinRL} is featured with completeness, hands-on tutorial and reproducibility that favors beginners: (i) at multiple levels of time granularity, {FinRL} simulates trading environments across various stock markets, including {NASDAQ}-100, {DJIA}, S\&P 500, {HSI}, {SSE} 50, and {CSI} 300; (ii) organized in a layered architecture with modular structure, {FinRL} provides fine-tuned state-of-the-art {DRL} algorithms ({DQN}, {DDPG}, {PPO}, {SAC}, A2C, {TD}3, etc.), commonly-used reward functions and standard evaluation baselines to alleviate the debugging workloads and promote the reproducibility, and (iii) being highly extendable, {FinRL} reserves a complete set of user-import interfaces. Furthermore, we incorporated three application demonstrations, namely single stock trading, multiple stock trading, and portfolio allocation. The {FinRL} library will be available on Github at link https://github.com/{AI}4Finance-{LLC}/{FinRL}-Library.},
	journaltitle = {{arXiv}:2011.09607 [cs, q-fin]},
	author = {Liu, Xiao-Yang and Yang, Hongyang and Chen, Qian and Zhang, Runjia and Yang, Liuqing and Xiao, Bowen and Wang, Christina Dan},
	urldate = {2021-08-27},
	date = {2020-11-18},
	eprinttype = {arxiv},
	eprint = {2011.09607},
	keywords = {Computer Science - Machine Learning, Quantitative Finance - Trading and Market Microstructure},
	file = {arXiv Fulltext PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\WFRW4AWI\\Liu et al. - 2020 - FinRL A Deep Reinforcement Learning Library for A.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\RIKSBSFD\\2011.html:text/html},
}

@article{freedman_economics_2015,
	title = {The Economics of Reproducibility in Preclinical Research},
	volume = {13},
	issn = {1545-7885},
	url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1002165},
	doi = {10.1371/journal.pbio.1002165},
	abstract = {Low reproducibility rates within life science research undermine cumulative knowledge production and contribute to both delays and costs of therapeutic drug development. An analysis of past studies indicates that the cumulative (total) prevalence of irreproducible preclinical research exceeds 50\%, resulting in approximately {US}\$28,000,000,000 ({US}\$28B)/year spent on preclinical research that is not reproducible—in the United States alone. We outline a framework for solutions and a plan for long-term improvements in reproducibility rates that will help to accelerate the discovery of life-saving therapies and cures.},
	pages = {e1002165},
	number = {6},
	journaltitle = {{PLOS} Biology},
	shortjournal = {{PLOS} Biology},
	author = {Freedman, Leonard P. and Cockburn, Iain M. and Simcoe, Timothy S.},
	urldate = {2021-08-27},
	date = {2015-06-09},
	langid = {english},
	note = {Publisher: Public Library of Science},
	keywords = {Reproducibility, Drug discovery, Drug research and development, Drug therapy, Economics, Finance, Internet, Peer review},
	file = {Full Text PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\UHQZM79Z\\Freedman et al. - 2015 - The Economics of Reproducibility in Preclinical Re.pdf:application/pdf;Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\KJJENIZB\\article.html:text/html},
}

@article{geyer-klingeberg_meta-analysis_2020,
	title = {Meta-analysis in finance research: Opportunities, challenges, and contemporary applications},
	volume = {71},
	issn = {1057-5219},
	url = {https://www.sciencedirect.com/science/article/pii/S105752192030168X},
	doi = {10.1016/j.irfa.2020.101524},
	shorttitle = {Meta-analysis in finance research},
	abstract = {The number of empirical research studies in finance exhibits a strong upward trajectory, which often produces large differences in empirical results and impedes the drawing of consistent conclusions in relation to the phenomenon under examination. This creates demand for methods like meta-analysis that objectively consolidate and evaluate the empricial literature in a research field. Meta-analysis is a group of statistical methods to aggregate prior empirical studies, to discover and explain consistencies as well as inconsistencies within reported results, and to detect and filter out distorting effects from publication selection or model misspecification. While meta-analysis is a standard tool for research synthesis and evidence-based decisions in many related research disciplines, such as management, marketing, or economics, it has been rarely applied in finance. The goal of this article is to provide a comprehensive overview and discussion of the opportunities of meta-analytical research in finance, to present recent applications of meta-analysis in finance, as well as to discuss related challenges and limitations. Thereby, we aim at increasing the awareness and acceptance of meta-analysis and stimulating its future application in the finance field.},
	pages = {101524},
	journaltitle = {International Review of Financial Analysis},
	shortjournal = {International Review of Financial Analysis},
	author = {Geyer-Klingeberg, Jerome and Hang, Markus and Rathgeber, Andreas},
	urldate = {2021-08-28},
	date = {2020-10-01},
	langid = {english},
	keywords = {Financial economics, Meta-analysis, Publication bias, Reviews, Synthesis},
	file = {ScienceDirect Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\FKX96BD9\\S105752192030168X.html:text/html},
}

@article{hardwicke_empirical_nodate,
	title = {An empirical assessment of transparency and reproducibility-related research practices in the social sciences (2014–2017)},
	volume = {7},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rsos.190806},
	doi = {10.1098/rsos.190806},
	abstract = {Serious concerns about research quality have catalysed a number of reform initiatives intended to improve transparency and reproducibility and thus facilitate self-correction, increase efficiency and enhance research credibility. Meta-research has evaluated the merits of some individual initiatives; however, this may not capture broader trends reflecting the cumulative contribution of these efforts. In this study, we manually examined a random sample of 250 articles in order to estimate the prevalence of a range of transparency and reproducibility-related indicators in the social sciences literature published between 2014 and 2017. Few articles indicated availability of materials (16/151, 11\% [95\% confidence interval, 7\% to 16\%]), protocols (0/156, 0\% [0\% to 1\%]), raw data (11/156, 7\% [2\% to 13\%]) or analysis scripts (2/156, 1\% [0\% to 3\%]), and no studies were pre-registered (0/156, 0\% [0\% to 1\%]). Some articles explicitly disclosed funding sources (or lack of; 74/236, 31\% [25\% to 37\%]) and some declared no conflicts of interest (36/236, 15\% [11\% to 20\%]). Replication studies were rare (2/156, 1\% [0\% to 3\%]). Few studies were included in evidence synthesis via systematic review (17/151, 11\% [7\% to 16\%]) or meta-analysis (2/151, 1\% [0\% to 3\%]). Less than half the articles were publicly available (101/250, 40\% [34\% to 47\%]). Minimal adoption of transparency and reproducibility-related research practices could be undermining the credibility and efficiency of social science research. The present study establishes a baseline that can be revisited in the future to assess progress.},
	pages = {190806},
	number = {2},
	journaltitle = {Royal Society Open Science},
	author = {Hardwicke, Tom E. and Wallach, Joshua D. and Kidwell, Mallory C. and Bendixen, Theiss and Crüwell, Sophia and Ioannidis, John P. A.},
	urldate = {2021-08-28},
	note = {Publisher: Royal Society},
	keywords = {reproducibility, meta-research, open science, social sciences, transparency},
	file = {Full Text PDF:C\:\\Users\\e-CJD\\Zotero\\storage\\FXVCCZA7\\Hardwicke et al. - An empirical assessment of transparency and reprod.pdf:application/pdf},
}

@incollection{xie_knitr_2014,
	title = {knitr: A Comprehensive Tool for Reproducible Research in R},
	isbn = {978-1-315-37346-1},
	shorttitle = {knitr},
	abstract = {Reproducibility is the ultimate standard by which scientific findings are judged. From the computer science perspective, reproducible research is often related to literate programming [13], a paradigm conceived by Donald Knuth, and the basic idea is to combine computer code and software 4documentation in the same document; the code and documentation can be identified by different special markers. We can either compile the code and mix the results with documentation or extract the source code from the document. To some extent, this implies reproducibility because everything is generated automatically from computer code, and the code can reflect all the details about computing.},
	booktitle = {Implementing Reproducible Research},
	publisher = {Chapman and Hall/{CRC}},
	author = {Xie, Yihui},
	date = {2014},
	note = {Num Pages: 29},
}

@book{gandrud_reproducible_2020,
	location = {Boca Raton},
	edition = {3},
	title = {Reproducible Research with R and {RStudio}},
	isbn = {978-0-429-03185-4},
	pagetotal = {298},
	publisher = {Chapman and Hall/{CRC}},
	author = {Gandrud, Christopher},
	date = {2020-02-27},
	doi = {10.1201/9780429031854},
}

@book{atmanspacher_reproducibility_2016,
	title = {Reproducibility: Principles, Problems, Practices, and Prospects},
	isbn = {978-1-118-86497-5},
	shorttitle = {Reproducibility},
	pagetotal = {600},
	publisher = {John Wiley \& Sons},
	author = {Atmanspacher, Harald and Maasen, Sabine},
	date = {2016-07-05},
	langid = {english},
	note = {Google-Books-{ID}: {rdQ}9CgAAQBAJ},
	keywords = {Education / General, Mathematics / Probability \& Statistics / General, Science / Applied Sciences, Science / Research \& Methodology},
}

@article{tetens_reproducibility_2016,
	title = {Reproducibility, Objectivity, Invariance},
	pages = {13--20},
	journaltitle = {Reproducibility: Principles, Problems, Practices, and Prospects},
	author = {Tetens, Holm},
	date = {2016},
	note = {Publisher: John Wiley \& Sons, Inc. Hoboken, {NJ}, {USA}},
	file = {Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\J3A6N3EK\\books.html:text/html},
}

@article{stahel_statistical_2016,
	title = {Statistical issues in reproducibility},
	pages = {87--114},
	journaltitle = {Reproducibility: Principles, problems, practices, and prospects},
	author = {Stahel, Werner A.},
	date = {2016},
	file = {Full Text:C\:\\Users\\e-CJD\\Zotero\\storage\\29GT47TS\\Stahel - 2016 - Statistical issues in reproducibility.pdf:application/pdf;Snapshot:C\:\\Users\\e-CJD\\Zotero\\storage\\VJSPXS4F\\books.html:text/html},
}
@article{fama1973,
	title = {Risk, Return, and Equilibrium: Empirical Tests},
	author = {Fama, Eugene F. and MacBeth, James D.},
	year = {1973},
	date = {1973},
	journal = {Journal of Political Economy},
	pages = {607--636},
	volume = {81},
	number = {3},
	url = {https://www.jstor.org/stable/1831028},
	note = {Publisher: University of Chicago Press}
}
